{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import glob, os, random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to scale the YouTube videos. The unscaled YouTube data are stored on the p3-1 instance in `/home/ec2-user/bopbot_data/yt_data.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data. [This takes a few minutes.]\n",
    "with open('yt_data.json', 'r') as fp:\n",
    "    yt_data = json.load(fp)\n",
    "len(yt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert loaded data to numpy.\n",
    "for key in yt_data:\n",
    "    yt_data[key] = np.array(yt_data[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4352, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt_data['yt0000'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_zeros(sequence):\n",
    "    '''Takes a 3d array of size Nx300x28 that represents a sequence of \n",
    "    300-frame clips from a single video. The last clip is padded with zeros\n",
    "    to reach length 300. This function removes the zeros so the remaining \n",
    "    frames can be scaled and centered.'''\n",
    "    #Reshape to 2dim array and pull out the zeros frames.\n",
    "    sequence = sequence.reshape(-1,28)\n",
    "    zero_frames = []\n",
    "    for frame in range(sequence.shape[0]):\n",
    "        if np.all(sequence[frame] == np.zeros(28)):\n",
    "            zero_frames.append(frame)\n",
    "    sequence = np.delete(sequence,zero_frames, axis=0)\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_sequence(sequence):\n",
    "    '''Takes an input dance sequence as 2d numpy array of size Nx28.\n",
    "    Scales the array so that all frames are within a 500x256 canvas\n",
    "    when rendered. Centers the array on the canvas. Returns the\n",
    "    scaled array.'''\n",
    "    #Get the range of the y-axis and scale to 95% of the 256 canvas.\n",
    "    sequence = sequence.reshape(-1,14,2)\n",
    "    seq_min = np.array([500,256])\n",
    "    seq_max = np.array([0,0])\n",
    "    for frame in sequence:\n",
    "        frame_min = np.min(frame, axis=0)\n",
    "        frame_max = np.max(frame, axis=0)\n",
    "        if frame_min[0] < seq_min[0]:\n",
    "            seq_min[0] = frame_min[0]\n",
    "        if frame_min[1] < seq_min[1]:\n",
    "            seq_min[1] = frame_min[1]\n",
    "        if frame_max[0] > seq_max[0]:\n",
    "            seq_max[0] = frame_max[0]\n",
    "        if frame_max[1] > seq_max[1]:\n",
    "            seq_max[1] = frame_max[1]\n",
    "    y_range = seq_max[1]-seq_min[1]\n",
    "    x_range = seq_max[0]-seq_min[0]\n",
    "    #Scale the y values to expand/contract to 95% of the canvas.\n",
    "    #Get a random draw for this video from 95+/-1\n",
    "    draw = random.uniform(0.94,0.96)\n",
    "    N = 256*draw/y_range\n",
    "    sequence = sequence*N\n",
    "\n",
    "    #Find the center point of the new x-range.\n",
    "    x_center = (x_range*N)/2\n",
    "    #Shift the x values left/right so center of range falls at center of canvas (250).\n",
    "    shift_x = 250-(x_center+(seq_min[0]*N))\n",
    "    #Pull out the x-axis and y-axis values separately.\n",
    "    x_vals = sequence[:,:,0]\n",
    "    y_vals = sequence[:,:,1]\n",
    "    #Shift the x values.\n",
    "    shifted_x_vals = x_vals+shift_x\n",
    "    #Put the shifted x values back into the array.\n",
    "    sequence = np.dstack([shifted_x_vals,y_vals]) \n",
    "\n",
    "    #Determine whether any of the scaled/shifted x values are out of range.\n",
    "    new_min = np.array([500,256])\n",
    "    new_max = np.array([0,0])\n",
    "    for frame in sequence:\n",
    "        frame_min = np.min(frame, axis=0)\n",
    "        frame_max = np.max(frame, axis=0)\n",
    "        if frame_min[0] < new_min[0]:\n",
    "            new_min[0] = frame_min[0]\n",
    "        if frame_min[1] < new_min[1]:\n",
    "            new_min[1] = frame_min[1]\n",
    "        if frame_max[0] > new_max[0]:\n",
    "            new_max[0] = frame_max[0]\n",
    "        if frame_max[1] > new_max[1]:\n",
    "            new_max[1] = frame_max[1]\n",
    "\n",
    "    #Scale a second time if any x values are out of range.\n",
    "    M=1\n",
    "    if ((new_min[0] < 0) or (new_max[0] > 500)):\n",
    "        #Calculate the scaling factor needed to get within range.\n",
    "        if 0-new_min[0] > new_max[0]-500:\n",
    "            M = (500*draw)/(500-new_min[0])\n",
    "        else:\n",
    "            M = (500*draw)/(new_max[0])\n",
    "        sequence = sequence*M\n",
    "    #Find the center point of the new y-range.\n",
    "    y_center = (y_range*N*M)/2\n",
    "    #Shift the y values up/down so center of range falls at center of canvas (128).\n",
    "    #(This needs to happen after the second scaling.)\n",
    "    shift_y = 128-(y_center+(new_min[1]*M))\n",
    "    #Pull out the x-axis and y-axis values separately.\n",
    "    x_vals = sequence[:,:,0]\n",
    "    y_vals = sequence[:,:,1]\n",
    "    #Shift the y values.\n",
    "    shifted_y_vals = y_vals+shift_y\n",
    "    #Put the shifted axes back together.\n",
    "    sequence = np.dstack([x_vals,shifted_y_vals]) \n",
    "\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 52.9 MiB for an array with shape (495157, 14) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f7548ccf8987>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myt_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnew_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myt_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mnew_yt_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-db9eb11a7a12>\u001b[0m in \u001b[0;36mscale_sequence\u001b[0;34m(sequence)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0my_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m#Shift the x values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mshifted_x_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_vals\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mshift_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;31m#Put the shifted x values back into the array.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshifted_x_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_vals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 52.9 MiB for an array with shape (495157, 14) and data type float64"
     ]
    }
   ],
   "source": [
    "new_yt_dict = {}\n",
    "for key in yt_data:\n",
    "    new_seq = remove_zeros(yt_data[key])\n",
    "    new_yt_dict[key] = scale_sequence(new_seq).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save new data\n",
    "\n",
    "Save the cleaned and scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../bopbot_data/yt_scaled.json', 'w') as fp:\n",
    "    json.dump(new_yt_dict, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viz\n",
    "\n",
    "Visualize the out of range sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in out_of_range_dict:\n",
    "    video = d2m_dict_data[key]\n",
    "    for i in range(video.shape[0]):\n",
    "        frame_num = f'{i:05d}'\n",
    "        img = vis_single(video[i], f'rendered/outfile_{frame_num}.jpg')\n",
    "    images = glob.glob(\"rendered/*.jpg\")\n",
    "    make_video(images, outvid = f'rendered/{key}.avi',fps=20)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function from D2M takes a numpy array, \"pose\" of the 14 D2M keypoints,\n",
    "# saves a rendered figure as \"outfile\".\n",
    "def vis_single(pose, outfile):\n",
    "  colors = [[255, 0, 0], [255, 85, 0], [255, 170, 0], [255, 255, 0], [170, 255, 0], [85, 255, 0], [0, 255, 0], \\\n",
    "          [0, 255, 85], [0, 255, 170], [0, 255, 255], [0, 170, 255], [0, 85, 255], [0, 0, 255], [85, 0, 255], \\\n",
    "          [170, 0, 255], [255, 0, 255], [255, 0, 170], [255, 0, 85]]\n",
    "\n",
    "  # find connection in the specified sequence, center 29 is in the position 15\n",
    "  limbSeq = [[2,3], [2,6], [3,4], [4,5], [6,7], [7,8], [2,9], [9,10], \\\n",
    "           [10,11], [2,12], [12,13], [13,14], [2,1], [1,15], [15,17], \\\n",
    "           [1,16], [16,18], [3,17], [6,18]]\n",
    "\n",
    "  neglect = [14,15,16,17]\n",
    "\n",
    "  for t in range(1):\n",
    "    #break\n",
    "    canvas = np.ones((256,500,3), np.uint8)*255\n",
    "    canvas[0] = 1\n",
    "    canvas[255] = 1\n",
    "    for i in range(256):\n",
    "        canvas[i][0] = 1\n",
    "        canvas[i][499] = 1\n",
    "\n",
    "    thisPeak = pose\n",
    "    for i in range(18):\n",
    "      if i in neglect:\n",
    "        continue\n",
    "      if thisPeak[i,0] == -1:\n",
    "        continue\n",
    "      cv2.circle(canvas, tuple(thisPeak[i,0:2].astype(int)), 4, colors[i], thickness=-1)\n",
    "\n",
    "    for i in range(17):\n",
    "      limbid = np.array(limbSeq[i])-1\n",
    "      if limbid[0] in neglect or limbid[1] in neglect:\n",
    "        continue\n",
    "      X = thisPeak[[limbid[0],limbid[1]], 1]\n",
    "      Y = thisPeak[[limbid[0],limbid[1]], 0]\n",
    "      if X[0] == -1 or Y[0]==-1 or X[1]==-1 or Y[1]==-1:\n",
    "        continue\n",
    "      stickwidth = 4\n",
    "      cur_canvas = canvas.copy()\n",
    "      mX = np.mean(X)\n",
    "      mY = np.mean(Y)\n",
    "      length = ((X[0] - X[1]) ** 2 + (Y[0] - Y[1]) ** 2) ** 0.5\n",
    "      angle = math.degrees(math.atan2(X[0] - X[1], Y[0] - Y[1]))\n",
    "      polygon = cv2.ellipse2Poly((int(mY),int(mX)), (int(length/2), stickwidth), int(angle), 0, 360, 1)\n",
    "      cv2.fillConvexPoly(cur_canvas, polygon, colors[i])\n",
    "      canvas = cv2.addWeighted(canvas, 0.4, cur_canvas, 0.6, 0)\n",
    "    cv2.imwrite(outfile,canvas)\n",
    "    return canvas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from Stephanie's notebook.\n",
    "def make_video(images, outvid=None, fps=5, size=None,\n",
    "               is_color=True, format='MP42'):\n",
    "    \"\"\"\n",
    "    Create a video from a list of images.\n",
    " \n",
    "    @param      outvid      output video\n",
    "    @param      images      list of images to use in the video\n",
    "    @param      fps         frame per second\n",
    "    @param      size        size of each frame\n",
    "    @param      is_color    color\n",
    "    @param      format      see http://www.fourcc.org/codecs.php\n",
    "    @return                 see http://opencv-python-tutroals.readthedocs.org/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
    " \n",
    "    The function relies on http://opencv-python-tutroals.readthedocs.org/en/latest/.\n",
    "    By default, the video will have the size of the first image.\n",
    "    It will resize every image to this size before adding them to the video.\n",
    "    MODIFIED FROM: http://www.xavierdupre.fr/blog/2016-03-30_nojs.html\n",
    "    \"\"\"\n",
    "    from cv2 import VideoWriter, VideoWriter_fourcc, imread, resize\n",
    "    fourcc = VideoWriter_fourcc(*format)\n",
    "    vid = None\n",
    "    for image in images:\n",
    "        #print(image)\n",
    "        if not os.path.exists(image):\n",
    "            raise FileNotFoundError(image)\n",
    "        img = imread(image)\n",
    "        if vid is None:\n",
    "            if size is None:\n",
    "                size = img.shape[1], img.shape[0]\n",
    "            vid = VideoWriter(outvid, fourcc, float(fps), size, is_color)\n",
    "        if size[0] != img.shape[1] and size[1] != img.shape[0]:\n",
    "            img = resize(img, size)\n",
    "        vid.write(img)\n",
    "        os.remove(image)\n",
    "    vid.release()\n",
    "    return vid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
